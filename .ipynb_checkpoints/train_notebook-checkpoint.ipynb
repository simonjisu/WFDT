{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, filename, window=7, train=True, **kwargs):\n",
    "        self.foods = {\n",
    "            \"chinese\": [\"black bean sauce noodle\", \"fried rice\", \"hotpot(huoguo)\"], \n",
    "            \"indian\": [\"curry rice\"], \n",
    "            \"western\": [\"pasta\", \"pizza\", \"fried chicken\", \"hamburger\", \"steak\", \"hotdog\"], \n",
    "            \"korean\": [\"korean bbq\", \"kimchi stew\", \"soybean paste stew\",\"cold noodles\", \"bibimbap\"],\n",
    "            \"mexican\" : [\"taco\", \"burrito\"],\n",
    "            \"japanese\": [\"sushi\", \"donkatsu\"],\n",
    "            \"vietnam\": [\"pho\", \"banh mi thit\"]\n",
    "        }\n",
    "        if train:\n",
    "            self.foods_cate_dict = {k: i for i, k in enumerate(sorted(list(self.foods.keys())))}\n",
    "            all_foods = sorted([x for foods in self.foods.values() for x in foods])\n",
    "            self.food_dict = {v: i for i, v in enumerate(all_foods)}\n",
    "            self.workload_dict = {\"No work\": 0, \"Low\": 1, \"Normal\": 2, \"High\": 3}\n",
    "        else:\n",
    "            self.foods_cate_dict = kwargs[\"foods_cate_dict\"]\n",
    "            self.food_dict = kwargs[\"food_dict\"]\n",
    "            self.workload_dict = {\"No work\": 0, \"Low\": 1, \"Normal\": 2, \"High\": 3}\n",
    "            \n",
    "        with open(filename, \"r\") as file:\n",
    "            data = file.readlines()[1:]\n",
    "            \n",
    "        numericalize = lambda x: (\n",
    "            float(x[0]), int(x[1]), self.workload_dict.get(x[2]), \n",
    "            int(x[3]), self.foods_cate_dict.get(x[4]), self.food_dict.get(x[5])\n",
    "        ) \n",
    "        # load data and numericalize\n",
    "        # data: temperature, hometime, workload, earlymeeting, food\n",
    "        data = torch.FloatTensor([numericalize(line.rstrip(\"\\n\").split(\",\")) for line in data])\n",
    "        \n",
    "        # input columns = 5\n",
    "        y = []\n",
    "        X = []\n",
    "        for idx in torch.arange(1, len(data)+1-window):\n",
    "            # add what category food i ate yesterday\n",
    "            window_data = data[idx:idx+window, :]\n",
    "            ate_yesterday = data[(idx-1):(idx-1+window), -2]\n",
    "            X.append(torch.cat((window_data[:, :-2], ate_yesterday.view(-1, 1)), axis=1))\n",
    "            y.append(window_data[-1, -1].item())\n",
    "            \n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.X = torch.stack(X)        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodRecommendModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, bidirectional=True):\n",
    "        super(FoodRecommendModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        self.fc = nn.Linear(2*hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, (hiddens, cells) = self.lstm(x)  # hiddens: n_direct, B, H > B, \n",
    "        last_t_hiddens = torch.cat([h for h in hiddens], dim=1)\n",
    "        outputs = self.fc(last_t_hiddens)\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, x):\n",
    "        outputs = self.forward(x)\n",
    "        return torch.argmax(outputs, axis=1)\n",
    "    \n",
    "    def recommand(self, x, recommand_num=3):\n",
    "        outputs = self.forward(x)\n",
    "        return outputs.sort(descending=True).view(-1)[:recommand_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, loss_function, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for inputs, targets in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        predicts = model.predict(inputs).cpu()\n",
    "        total_correct += predicts.eq(targets.cpu()).sum().item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = total_loss / len(data_loader)\n",
    "    train_acc = total_correct / len(data_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            predicts = model.predict(inputs).cpu()\n",
    "            total_correct += predicts.eq(targets.cpu()).sum().item()\n",
    "        \n",
    "    test_loss = total_loss / len(data_loader)\n",
    "    test_acc = total_correct / len(data_loader.dataset)\n",
    "    model.to(device)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_train=\"./dinner_records_train.csv\"\n",
    "save_path_test=\"./dinner_records_test.csv\"\n",
    "window = 7\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_train_dataset = FoodDataset(save_path_train, window)\n",
    "preprocess_dict = {\n",
    "    \"foods_cate_dict\": food_train_dataset.foods_cate_dict,\n",
    "    \"food_dict\": food_train_dataset.food_dict,\n",
    "}\n",
    "food_test_dataset = FoodDataset(save_path_test, window, train=False, **preprocess_dict)\n",
    "\n",
    "food_train_loader = DataLoader(food_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "food_test_loader = DataLoader(food_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 64\n",
    "output_size = len(food_train_dataset.food_dict)\n",
    "num_layers = 1\n",
    "bidirectional = True\n",
    "n_step = 500\n",
    "wd_rate = 0.0001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FoodRecommendModel(input_size, hidden_size, output_size, num_layers, bidirectional).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=wd_rate)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=wd_rate)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 250, 450], gamma=0.5)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train - loss: 2.8438, acc: 11.48 %\n",
      "[1]  test - loss: 2.8408, acc: 10.34 %\n",
      "[51] train - loss: 1.8235, acc: 43.02 %\n",
      "[51]  test - loss: 4.5844, acc: 8.28 %\n",
      "[101] train - loss: 1.4034, acc: 54.77 %\n",
      "[101]  test - loss: 5.3566, acc: 5.52 %\n",
      "[151] train - loss: 1.2370, acc: 61.13 %\n",
      "[151]  test - loss: 5.6360, acc: 8.97 %\n",
      "[201] train - loss: 1.1358, acc: 62.79 %\n",
      "[201]  test - loss: 6.2336, acc: 7.59 %\n",
      "[251] train - loss: 1.0418, acc: 65.70 %\n",
      "[251]  test - loss: 6.4667, acc: 6.90 %\n",
      "[301] train - loss: 0.9176, acc: 70.82 %\n",
      "[301]  test - loss: 6.6275, acc: 10.34 %\n",
      "[351] train - loss: 0.8633, acc: 73.03 %\n",
      "[351]  test - loss: 6.7720, acc: 8.97 %\n",
      "[401] train - loss: 0.8282, acc: 74.69 %\n",
      "[401]  test - loss: 6.5911, acc: 9.66 %\n",
      "[451] train - loss: 0.7327, acc: 78.70 %\n",
      "[451]  test - loss: 6.9624, acc: 8.97 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for step in range(n_step):\n",
    "    train_loss, train_acc = train_model(model, food_train_loader, loss_function, optimizer, device)\n",
    "    test_loss, test_acc = test_model(model, food_test_loader, device)\n",
    "    scheduler.step()\n",
    "    if step % 50 == 0:\n",
    "        print(f\"[{step+1}] train - loss: {train_loss:.4f}, acc: {train_acc*100:.2f} %\")\n",
    "        print(f\"[{step+1}]  test - loss: {test_loss:.4f}, acc: {test_acc*100:.2f} %\")\n",
    "    if test_acc >= best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), \"best_acc_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
